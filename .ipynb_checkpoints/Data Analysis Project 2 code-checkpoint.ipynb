{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction to Data Science\n",
    "\n",
    "### Project 2\n",
    "\n",
    "### Student Name: Akram Reshad\n",
    "\n",
    "### Student Netid: amr10073\n",
    "\n",
    "### deadline: Dec 06, 2021, 11:59pm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting and Cleaning Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "movies_df = pd.read_csv (r'/Users/akram/Documents/Graduate School/NYU Fall 2021/Intro to Data Science/Data Analysis Project 2/movieReplicationSet.csv')\n",
    "movies_df = movies_df.rename({'Rambo: First Blood Part II' : 'Rambo: First Blood Part II (1985)'}, axis = 1) #The only movie without a year\n",
    "col_names = movies_df.columns\n",
    "mean_imputer = SimpleImputer()\n",
    "movies_df = pd.DataFrame(mean_imputer.fit_transform(movies_df))\n",
    "movies_df.columns = col_names\n",
    "\n",
    "### Getting columns into their own DataFrames\n",
    "rows,cols = movies_df.shape\n",
    "movie_ratings = movies_df.iloc[:,:400]\n",
    "sensation_assessment = movies_df.iloc[:,401:420]\n",
    "personality_assessment = movies_df.iloc[:,420:464]\n",
    "movie_experience = movies_df.iloc[:,465:474]\n",
    "gender = movies_df.iloc[:,474]\n",
    "only_child = movies_df.iloc[:,475]\n",
    "enjoy_movies_alone= movies_df.iloc[:,476]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#correlated_users[i] is the the ith users most correlated user\n",
    "correlated_users = [-1 for i in range(rows)] \n",
    "correlation_between_users = [-1 for i in range(rows)]\n",
    "corr_matrix = abs(movies_df.T.corr())\n",
    "\n",
    "for i in range(rows):\n",
    "    corr_matrix[i] = corr_matrix[i].drop([i])\n",
    "    correlated_users[i] = corr_matrix[i].idxmax(corr_matrix[i].max())\n",
    "    correlation_between_users[i] = corr_matrix[i].max()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Pair of most correlated users is:\n",
      "User 896 and User 831\n",
      "\n",
      "number of users whos highest correlated user is 896 is 301\n"
     ]
    }
   ],
   "source": [
    "print('The Pair of most correlated users is:')\n",
    "print('User', correlated_users[correlation_between_users.index(max(correlation_between_users))],\n",
    "      'and User', correlation_between_users.index(max(correlation_between_users)))\n",
    "\n",
    "print('')\n",
    "count = 0 \n",
    "for i in range(len(correlated_users)):\n",
    "    if correlated_users[i] == 896:\n",
    "        count +=1\n",
    "print('number of users whos highest correlated user is 896 is', count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  1.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With Correlation: 0.999542426149521\n"
     ]
    }
   ],
   "source": [
    "print('With Correlation:', max(correlation_between_users))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  1.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User 0 and User 583\n",
      "User 1 and User 831\n",
      "User 2 and User 896\n",
      "User 3 and User 364\n",
      "User 4 and User 896\n",
      "User 5 and User 99\n",
      "User 6 and User 239\n",
      "User 7 and User 896\n",
      "User 8 and User 896\n",
      "User 9 and User 1004\n"
     ]
    }
   ],
   "source": [
    "for i in range(0,10):\n",
    "    print('User', i,'and User', correlated_users[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "df_rating = movie_ratings\n",
    "\n",
    "df_pers = pd.concat([sensation_assessment, personality_assessment, movie_experience], axis= 1)\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(df_rating, df_pers, train_size=0.8, test_size=0.2, random_state=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training error  0.6097000059161142\n",
      "Validation error:  3.7156721567651783\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "linear_regressor = LinearRegression()\n",
    "\n",
    "linear_regressor.fit(X_train,y_train)\n",
    "\n",
    "valid_predictions = linear_regressor.predict(X_valid)\n",
    "train_predictions = linear_regressor.predict(X_train)\n",
    "print('Training error ', mean_squared_error(y_train, train_predictions))\n",
    "print('Validation error: ', mean_squared_error(y_valid, valid_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train error for Ridges 0.001, 0.6097000210818234\n",
      "Validation error for Ridges 0.001, 3.71422096385074\n",
      "\n",
      "Train error for Ridges 0.01, 0.6097015012654998\n",
      "Validation error for Ridges 0.01, 3.7012911041792154\n",
      "\n",
      "Train error for Ridges 0.1, 0.6098311181080476\n",
      "Validation error for Ridges 0.1, 3.583512539784067\n",
      "\n",
      "Train error for Ridges 1, 0.6153896429448558\n",
      "Validation error for Ridges 1, 2.943675235320678\n",
      "\n",
      "We choose the Ridge with the best prediction/lowest MSE, which is 1\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.metrics import mean_squared_error\n",
    "alphas = [.001, .01, .1, 1]\n",
    "ridge_regressors = []\n",
    "Train_predictions =[]\n",
    "Valid_predictions = []\n",
    "train_error = []\n",
    "valid_error = []\n",
    "for i,a in enumerate(alphas):\n",
    "    ridge_regressors.append(Ridge(alpha = a))\n",
    "    ridge_regressors[i].fit(X_train,y_train)\n",
    "    Train_predictions.append(ridge_regressors[i].predict(X_train))\n",
    "    Valid_predictions.append(ridge_regressors[i].predict(X_valid))\n",
    "    train_error.append(mean_squared_error(y_train, Train_predictions[i]))\n",
    "    valid_error.append(mean_squared_error(y_valid, Valid_predictions[i]))\n",
    "    \n",
    "    print('Train error for Ridges ' + str(a) + ',', train_error[i] )\n",
    "    print('Validation error for Ridges ' + str(a) + ',', valid_error[i])\n",
    "    print(\"\")\n",
    "\n",
    "print('We choose the Ridge with the best prediction/lowest MSE, which is', str(alphas[valid_error.index(min(valid_error))]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/akram/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:529: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.12538335108104093, tolerance: 0.10291452791720967\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/akram/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:529: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.18470399990303576, tolerance: 0.1228928902220582\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train error for Lassos 0.001, 0.6344647828183012\n",
      "Validation error for Lassos 0.001, 2.4121469116113565\n",
      "\n",
      "Train error for Lassos 0.01, 0.8917202015904482\n",
      "Validation error for Lassos 0.01, 1.363186335078768\n",
      "\n",
      "Train error for Lassos 0.1, 1.2004708808332134\n",
      "Validation error for Lassos 0.1, 1.2493994505896162\n",
      "\n",
      "Train error for Lassos 1, 1.217214495222191\n",
      "Validation error for Lassos 1, 1.2593598026555604\n",
      "\n",
      "We choose the Lasso with the best prediction/lowest MSE which is 0.1\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.metrics import mean_squared_error\n",
    "alphas = [.001, .01, .1, 1]\n",
    "lasso_regressors = []\n",
    "Train_predictions =[]\n",
    "Valid_predictions = []\n",
    "train_error = []\n",
    "valid_error = []\n",
    "for i,a in enumerate(alphas):\n",
    "    lasso_regressors.append(Lasso(alpha = a))\n",
    "    lasso_regressors[i].fit(X_train,y_train)\n",
    "    Train_predictions.append(lasso_regressors[i].predict(X_train))\n",
    "    Valid_predictions.append(lasso_regressors[i].predict(X_valid))\n",
    "    train_error.append(mean_squared_error(y_train, Train_predictions[i]))\n",
    "    valid_error.append(mean_squared_error(y_valid, Valid_predictions[i]))\n",
    "    \n",
    "    print('Train error for Lassos ' + str(a) + ',', train_error[i] )\n",
    "    print('Validation error for Lassos ' + str(a) + ',', valid_error[i])\n",
    "    print(\"\")\n",
    "    \n",
    "print('We choose the Lasso with the best prediction/lowest MSE which is', str(alphas[valid_error.index(min(valid_error))]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
